{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "week_8_document1.docx:['acquired' 'added' 'adjective' 'aid' 'algorithms' 'aligned' 'alignment'\n",
      " 'allows' 'also' 'analysis' 'annotated' 'annotating' 'annotation'\n",
      " 'annotations' 'another' 'applied' 'around' 'authentic' 'base' 'bilingual'\n",
      " 'called' 'comparable' 'comparison' 'completely' 'comprising'\n",
      " 'computational' 'considered' 'consistently' 'contain' 'containing'\n",
      " 'content' 'contextualised' 'corpora' 'corpus' 'corpus2' 'cover' 'create'\n",
      " 'derived' 'difficulty' 'effective' 'elementforelement' 'enabling'\n",
      " 'ensuring' 'entire' 'equivalent' 'etc' 'example' 'exploit' 'exposure'\n",
      " 'first' 'foreign' 'form' 'formation' 'formatted' 'fragments' 'frequency'\n",
      " 'fully' 'glossing' 'grammatical' 'grasp' 'hidden' 'identifying'\n",
      " 'including' 'indicating' 'information' 'interlinear' 'kind' 'knowledge'\n",
      " 'known' 'language' 'languages' 'learners' 'lemma' 'levels' 'linguistic'\n",
      " 'linguistics' 'lists' 'machine' 'main' 'make' 'manner' 'markov' 'may'\n",
      " 'means' 'million' 'models' 'morphology' 'much' 'multilingual' 'nonnative'\n",
      " 'noun' 'number' 'often' 'one' 'order' 'other1' 'parallel' 'parsed' 'part'\n",
      " 'particular' 'partofspeech' 'phrases' 'possible' 'postagging'\n",
      " 'pragmatics' 'prerequisite' 'process' 'processing' 'purposes'\n",
      " 'recognition' 'research' 'researchers' 'second' 'segments' 'semantics'\n",
      " 'sentence' 'sentences' 'sidebyside' 'smaller' 'specially' 'speech'\n",
      " 'structured' 'subject' 'subjected' 'tagging' 'tags' 'target' 'teaching'\n",
      " 'text' 'texts' 'three' 'trained' 'translating' 'translation'\n",
      " 'translations' 'treebanks' 'two' 'type' 'types' 'use' 'used' 'useful'\n",
      " 'users' 'using' 'usually' 'various' 'verb' 'word' 'words' 'work'\n",
      " 'working' 'writing']\n",
      "week_8_document2.txt:['academic' 'accepted' 'acme' 'act' 'additional' 'adrenocorticotropic'\n",
      " 'afflicted' 'alarm' 'almost' 'also' 'andor' 'another' 'anthology'\n",
      " 'anywhere' 'apparently' 'appointment' 'areas' 'aristotles' 'arousal'\n",
      " 'article' 'artist' 'ask' 'asking' 'asleep' 'audiences' 'audit'\n",
      " 'avalanche' 'awake' 'awaken' 'bachelor' 'back' 'bad' 'become' 'bed'\n",
      " 'bedtime' 'beeline' 'behind' 'believed' 'book' 'borderline' 'boring'\n",
      " 'brainstem' 'breakthroughs' 'briefly' 'bright' 'bring' 'broader'\n",
      " 'bystanders' 'called' 'calming' 'came' 'campus' 'cant' 'cared' 'career'\n",
      " 'carefully' 'cell' 'certainly' 'class' 'classes' 'classroom' 'closing'\n",
      " 'cocktail' 'comfortable' 'complete' 'complex' 'conceal' 'concentrate'\n",
      " 'concerts' 'conclusion' 'condition' 'conferences' 'connection'\n",
      " 'considered' 'contagion' 'contagious' 'conventions' 'conversations'\n",
      " 'corner' 'correlations' 'could' 'countless' 'covering' 'cure' 'curiosity'\n",
      " 'da' 'data' 'dated' 'day' 'dean' 'death' 'defense' 'defusing' 'derive'\n",
      " 'desperately' 'developed' 'devising' 'disappearing' 'discussion'\n",
      " 'discussions' 'disguised' 'displayed' 'dollars' 'done' 'donkey'\n",
      " 'dopaminergic' 'doubly' 'dr' 'drifts' 'dulcet' 'duration' 'dwindled'\n",
      " 'earl' 'effort' 'efforts' 'either' 'elaborate' 'else' 'encounter'\n",
      " 'encounters' 'enjoyed' 'enough' 'entire' 'epidemic' 'equally' 'erection'\n",
      " 'even' 'evening' 'eventually' 'everybody' 'everyone' 'exaggeration'\n",
      " 'exams' 'excused' 'expert' 'expertise' 'expiration' 'extinguished' 'eyes'\n",
      " 'face' 'fail' 'fair' 'fall' 'famous' 'fascinating' 'fascination' 'fetal'\n",
      " 'field' 'finally' 'finished' 'flame' 'flickering' 'fondly' 'foremost'\n",
      " 'frequently' 'fully' 'gather' 'gestation' 'gradually' 'grateful'\n",
      " 'groundbreaking' 'hand' 'happy' 'harmlessly' 'hearing' 'hears' 'heavy'\n",
      " 'help' 'highschool' 'hoped' 'hormonerelated' 'hundred' 'hung'\n",
      " 'hypothalamic' 'hypoxia' 'hysterical' 'ignorant' 'ignored' 'illfated'\n",
      " 'immediacy' 'impress' 'inevitably' 'ingenuity' 'inhibition' 'initial'\n",
      " 'inquisitive' 'insomnia' 'insomniacs' 'inspiratory' 'intended' 'interval'\n",
      " 'invitations' 'involved' 'joke' 'joy' 'keep' 'kept' 'kidnapping'\n",
      " 'laboratories' 'lasted' 'learning' 'least' 'lectures' 'led' 'length'\n",
      " 'leonardo' 'lids' 'life' 'lighting' 'long' 'loss' 'made' 'make' 'man'\n",
      " 'managed' 'manuscript' 'mate' 'mayor' 'meanwhile' 'mechanisms' 'meetings'\n",
      " 'megaphone' 'mention' 'mere' 'mesmerizing' 'meticulous' 'middle' 'minor'\n",
      " 'missed' 'moment' 'monograph' 'mostly' 'mouth' 'much' 'nation' 'nearly'\n",
      " 'needed' 'neuromuscular' 'never' 'new' 'nonetheless' 'nontechnical'\n",
      " 'notes' 'nothing' 'noting' 'number' 'obtain' 'office' 'often' 'one'\n",
      " 'orgasmic' 'origin' 'ovation' 'owner' 'painted' 'painting' 'paper'\n",
      " 'paralinguistic' 'paroxysmal' 'particularly' 'parties' 'path' 'peak'\n",
      " 'people' 'peptides' 'perhaps' 'period' 'perish' 'personality'\n",
      " 'pharmacological' 'phase' 'phenomenon' 'phone' 'physiologic' 'picture'\n",
      " 'placed' 'plot' 'popularize' 'portrait' 'possible' 'precise' 'predelay'\n",
      " 'presenting' 'president' 'priceless' 'problems' 'professional'\n",
      " 'professor' 'project' 'proud' 'proudly' 'publish' 'questions' 'quietly'\n",
      " 'quite' 'quotations' 'rarely' 'rate' 'reached' 'reality' 'realizing'\n",
      " 'reasons' 'recalled' 'received' 'recent' 'receptions' 'recipient'\n",
      " 'reflected' 'reflex' 'regarding' 'rejected' 'relation' 'relaxing'\n",
      " 'remarkable' 'remember' 'remembered' 'renaissance' 'render' 'repeatedly'\n",
      " 'represented' 'reputation' 'research' 'reticular' 'retire' 'reviewing'\n",
      " 'right' 'role' 'room' 'rude' 'ruined' 'rumored' 'sadly' 'sat'\n",
      " 'satisfaction' 'saw' 'science' 'search' 'seated' 'see' 'seeing' 'seemed'\n",
      " 'sees' 'selection' 'serotoninergic' 'served' 'share' 'short' 'showing'\n",
      " 'side' 'simply' 'situation' 'sleep' 'social' 'soft' 'someone' 'something'\n",
      " 'sometimes' 'somniferous' 'soon' 'spice' 'spindles' 'spoken'\n",
      " 'spontaneous' 'started' 'stifle' 'still' 'stopwatch' 'stories'\n",
      " 'stretching' 'students' 'subject' 'suddenly' 'suffered' 'suicidal'\n",
      " 'surreptitiously' 'susceptibility' 'suspected' 'swallow' 'systems' 'take'\n",
      " 'temporary' 'terrorist' 'thanks' 'theories' 'thing' 'time' 'tomorrow'\n",
      " 'tones' 'topic' 'tried' 'trigger' 'type' 'unable' 'unconscious'\n",
      " 'uncontrollable' 'understand' 'unfortunate' 'unreadable' 'upon' 'urgent'\n",
      " 'urinates' 'used' 'value' 'vickers' 'vinci' 'wait' 'wake' 'wall' 'warm'\n",
      " 'way' 'ways' 'wedding' 'whether' 'wind' 'without' 'work' 'world' 'worlds'\n",
      " 'would' 'writing' 'yawn' 'yawnby' 'yawning' 'yawnings' 'yawnrelated'\n",
      " 'yawns' 'years']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"I provide a .zip containing .txt and .docx files\n",
    "For each file, remove punctuation and stop words\n",
    "Produce a single .dat file containing the name of the file in quotes, a colon, \n",
    "then a list of words separated by commas. \n",
    "The list of words per file should be unique. Do not include URLs or phone numbers.\n",
    "\"\"\"\n",
    "import os\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import readDocx\n",
    "import zipfile\n",
    "import re\n",
    "with zipfile.ZipFile(\"week_8_documents.zip\",\"r\") as zip_ref:\n",
    "    zip_ref.extractall()\n",
    "fileword = open('week_8_document1.docx', 'r')\n",
    "fileword1 = readDocx.getText('week_8_document1.docx')\n",
    "filetxt = open('week_8_document2.txt', 'r')\n",
    "filetxt1 = filetxt.read().replace('\\n', '')\n",
    "punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~—–’“”'''\n",
    "filewordnohttp = re.sub(r'(https|http)?:\\/\\/(\\w|\\.|\\/|\\?|\\=|\\&|\\%)*\\b', '', fileword1, flags=re.MULTILINE)\n",
    "filetxtnohttp = re.sub(r'(https|http)?:\\/\\/(\\w|\\.|\\/|\\?|\\=|\\&|\\%)*\\b', '', filetxt1, flags=re.MULTILINE)\n",
    "filewordnohttp1 = re.sub(r'((1-\\d{3}-\\d{3}-\\d{4})|(\\(\\d{3}\\) \\d{3}-\\d{4})|(\\d{3}-\\d{3}-\\d{4}))$', '', filewordnohttp,flags=re.MULTILINE)\n",
    "filetxtnohttp1 = re.sub(r'(https|http)?:\\/\\/(\\w|\\.|\\/|\\?|\\=|\\&|\\%)*\\b', '', filetxtnohttp, flags=re.MULTILINE)\n",
    "file1nopunc = ''.join(c for c in filewordnohttp1 if c not in punctuations).lower()\n",
    "file2nopunc = ''.join(c for c in filetxtnohttp1 if c not in punctuations).lower()\n",
    "stopword = stopwords.words('english')\n",
    "word_tokensdocx = nltk.word_tokenize(file1nopunc)\n",
    "removing_stopwordsdocx = [word for word in word_tokensdocx if word not in stopword]\n",
    "word_tokenstext = nltk.word_tokenize(file2nopunc)\n",
    "removing_stopwordstext = [word for word in word_tokenstext if word not in stopword]\n",
    "answerdocx = np.array(removing_stopwordsdocx)\n",
    "finalanswerdocx = np.unique(answerdocx)\n",
    "answertxt = np.array(removing_stopwordstext)\n",
    "finalanswertxt = np.unique(answertxt)\n",
    "final = str(os.path.basename('week_8_document1.docx')) + \":\" + str(finalanswerdocx) + \"\\n\" + str(os.path.basename('week_8_document2.txt')) + \":\" + str(finalanswertxt)\n",
    "finalfile = open(\"finalfile.dat\", \"w\")\n",
    "finalfile.write(final)\n",
    "finalfile.close()\n",
    "finalfile = open(\"finalfile.dat\", \"r\")\n",
    "print(finalfile.read())\n",
    "finalfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
